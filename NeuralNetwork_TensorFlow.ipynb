{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM\n",
    "\n",
    "ニューラルネットワークで排他的論理和回路のモデル ver. softmax with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "tensorflow 1.3.0\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"tensorflow\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルクラス定義\n",
    "class NN():\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param in_size: 入力層のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        self.in_size = in_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        # プレースホルダー\n",
    "        self.placeholder_x = tf.placeholder(tf.float32, shape=[None, self.in_size], name=\"placeholder_x\")\n",
    "        self.placeholder_t = tf.placeholder(tf.float32, shape=[None, self.out_size], name=\"placeholder_t\")\n",
    "        # 順伝播のネットワークを作成する\n",
    "        self.b1 = tf.Variable(tf.random_normal([self.hidden_size]), name=\"b1\") # 入力層のバイアス\n",
    "        self.w1= tf.Variable(tf.random_normal([self.in_size, self.hidden_size]), name=\"w1\") # 入力層の重み\n",
    "        self.h1 = tf.sigmoid(tf.matmul(self.placeholder_x, self.w1) + self.b1)\n",
    "        self.b2 = tf.Variable(tf.random_normal([self.hidden_size]), name=\"b2\") # 隠れ層のバイアス\n",
    "        self.w2 = tf.Variable(tf.random_normal([self.hidden_size, self.hidden_size]), name=\"w2\") # 隠れ層の重み\n",
    "        self.h2 = tf.sigmoid(tf.matmul(self.h1, self.w2) + self.b2)\n",
    "        self.b3 = tf.Variable(tf.random_normal([self.out_size]), name=\"b2\") # 出力層のバイアス\n",
    "        self.w3 = tf.Variable(tf.random_normal([self.hidden_size, self.out_size]), name=\"w3\") # 出力層の重み\n",
    "        self.y = tf.nn.softmax(tf.matmul(self.h2, self.w3) + self.b3)\n",
    "        # クロスエントロピーを計算する\n",
    "        self.cross_entropy = -tf.reduce_sum(self.placeholder_t*tf.log(self.y))\n",
    "        # 勾配を計算する\n",
    "        self.optimizer = tf.train.AdamOptimizer(0.01)\n",
    "        self.train_op = self.optimizer.minimize(self.cross_entropy)\n",
    "        # 正確度を計算する\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.y, 1), tf.argmax(self.placeholder_t, 1)), \"float\"))\n",
    "        # セッション開始\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(self.init) \n",
    "    \n",
    "    def __call__(self, x, t=None, train=False):\n",
    "        # 順伝播の計算を行う関数\n",
    "        # :param x: 入力値\n",
    "        # :param t: 正解のラベル\n",
    "        # :param train: 学習かどうか\n",
    "        # :return: 計算した損失 or 予測したラベル\n",
    "        fetches = self.y\n",
    "        feed_dict = {}\n",
    "        feed_dict[self.placeholder_x] = x\n",
    "        if train:\n",
    "            fetches = [self.train_op, self.cross_entropy, self.accuracy, self.b1, self.w1, self.b2, self.w2, self.b3, self.w3]\n",
    "            feed_dict[self.placeholder_t] = t\n",
    "        cvalues = self.sess.run(fetches, feed_dict=feed_dict) # 計算\n",
    "        if train:\n",
    "            _, loss, accuracy = cvalues[0], cvalues[1], cvalues[2] # 損失と正確度だけ返却する\n",
    "            return loss, accuracy\n",
    "        else:\n",
    "            return np.argmax(cvalues) # cvaluesにself.yの計算結果が入る\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "epoch:\t500\ttotal loss:\t0.03256687521934509\tmean accuracy:\t1.0\ttime:\t0:00:00.631843\n",
      "epoch:\t1000\ttotal loss:\t0.008058303035795689\tmean accuracy:\t1.0\ttime:\t0:00:00.611837\n",
      "epoch:\t1500\ttotal loss:\t0.0038142483681440353\tmean accuracy:\t1.0\ttime:\t0:00:00.624347\n",
      "epoch:\t2000\ttotal loss:\t0.0022085041273385286\tmean accuracy:\t1.0\ttime:\t0:00:00.616167\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "EPOCH_NUM = 2000\n",
    "HIDDEN_SIZE = 5\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# 教師データ\n",
    "train_data = [\n",
    "    [[0, 0], [0]],\n",
    "    [[1, 0], [1]],\n",
    "    [[0, 1], [1]],\n",
    "    [[1, 1], [0]]\n",
    "]\n",
    "\n",
    "# 教師データを変換\n",
    "in_size = len(train_data[0][0]) #  入力サイズ\n",
    "out_size = in_size # 出力サイズ\n",
    "N = len(train_data) # 教師データの総数\n",
    "train_x, train_t = [], []\n",
    "for x, t in train_data:\n",
    "    train_x.append(x)\n",
    "    t_ = np.zeros(out_size)\n",
    "    t_[t[0]] = 1\n",
    "    train_t.append(t_)\n",
    "train_x = np.array(train_x, dtype=\"float32\")\n",
    "train_t = np.array(train_t, dtype=\"float32\")\n",
    "\n",
    "# モデルの定義\n",
    "model = NN(in_size=in_size, hidden_size=HIDDEN_SIZE, out_size=out_size)\n",
    "\n",
    "# 学習開始\n",
    "print(\"Train\")\n",
    "st = datetime.datetime.now()\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    # ミニバッチ学習\n",
    "    perm = np.random.permutation(N) # ランダムな整数列リストを取得\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for i in range(0, N, BATCH_SIZE): \n",
    "        x = train_x[perm[i:i+BATCH_SIZE]]\n",
    "        t = train_t[perm[i:i+BATCH_SIZE]]\n",
    "        loss, accuracy = model(x=x, t=t, train=True)\n",
    "        total_loss += loss\n",
    "        total_accuracy += accuracy\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        ed = datetime.datetime.now()\n",
    "        print(\"epoch:\\t{}\\ttotal loss:\\t{}\\tmean accuracy:\\t{}\\ttime:\\t{}\".format(epoch+1, total_loss, total_accuracy/(N/BATCH_SIZE), ed-st))\n",
    "        st = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict\n",
      "x:\t[1, 0]\t=>\ty:\t1\n",
      "x:\t[0, 0]\t=>\ty:\t0\n",
      "x:\t[1, 1]\t=>\ty:\t0\n",
      "x:\t[0, 1]\t=>\ty:\t1\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "print(\"\\nPredict\")\n",
    "def predict(model, x):\n",
    "    y = model(x=[x], train=False)\n",
    "    print(\"x:\\t{}\\t=>\\ty:\\t{}\".format(x, y))\n",
    "\n",
    "# 予測\n",
    "predict(model, [1, 0])\n",
    "predict(model, [0, 0])\n",
    "predict(model, [1, 1])\n",
    "predict(model, [0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
