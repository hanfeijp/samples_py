{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM\n",
    "\n",
    "ニューラルネットワークでアイリスデータ分類 ver. softmax with Chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from chainer import Chain, Variable, cuda, optimizer, optimizers, serializers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "pandas 0.20.3\n",
      "scikit-learn 0.18.2\n",
      "chainer 2.0.2\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"pandas\", \"scikit-learn\", \"chainer\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ\n",
    "\n",
    "N = 100\n",
    "in_size = 4\n",
    "out_size = 3\n",
    "iris = datasets.load_iris()\n",
    "data = pd.DataFrame(data= np.c_[iris[\"data\"], iris[\"target\"]], columns= iris[\"feature_names\"] + [\"target\"])\n",
    "data = np.array(data.values)\n",
    "perm = np.random.permutation(len(data))\n",
    "data = data[perm]\n",
    "train, test = np.split(data, [N])\n",
    "train_x, train_y, test_x, test_y = [], [], [], []\n",
    "for t in train:\n",
    "    train_x.append(t[0:4])\n",
    "    train_y.append(t[4])\n",
    "for t in test:\n",
    "    test_x.append(t[0:4])\n",
    "    test_y.append(t[4])\n",
    "train_x = np.array(train_x, dtype=\"float32\")\n",
    "train_y = np.array(train_y, dtype=\"int32\")\n",
    "test_x = np.array(test_x, dtype=\"float32\")\n",
    "test_y = np.array(test_y, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルクラス定義\n",
    "\n",
    "class NN(Chain):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param in_size: 入力層のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        super(NN, self).__init__(\n",
    "            xh = L.Linear(in_size, hidden_size),\n",
    "            hh = L.Linear(hidden_size, hidden_size),\n",
    "            hy = L.Linear(hidden_size, out_size)\n",
    "        )\n",
    " \n",
    "    def __call__(self, x, y=None, train=False):\n",
    "        # 順伝播の計算を行う関数\n",
    "        # :param x: 入力値\n",
    "        # :param t: 正解のラベル\n",
    "        # :param train: 学習かどうか\n",
    "        # :return: 計算した損失 or 予測したラベル\n",
    "        x = Variable(x)\n",
    "        if train:\n",
    "            y = Variable(y)\n",
    "        h = F.sigmoid(self.xh(x))\n",
    "        h = F.sigmoid(self.hh(h))\n",
    "        y_ = F.softmax(self.hy(h))\n",
    "        if train:\n",
    "            loss, accuracy = F.softmax_cross_entropy(y_, y), F.accuracy(y_, y)\n",
    "            return loss, accuracy\n",
    "        else:\n",
    "            return np.argmax(y_.data)\n",
    " \n",
    "    def reset(self):\n",
    "        # 勾配の初期化\n",
    "        self.zerograds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "epoch:\t10\ttotal loss:\t5.461614608764648\tmean accuracy:\t0.3500000059604645\ttime:\t0:00:00.070610\n",
      "epoch:\t20\ttotal loss:\t5.385353684425354\tmean accuracy:\t0.3999999940395355\ttime:\t0:00:00.069062\n",
      "epoch:\t30\ttotal loss:\t5.2665863037109375\tmean accuracy:\t0.6600000023841858\ttime:\t0:00:00.067124\n",
      "epoch:\t40\ttotal loss:\t5.046608746051788\tmean accuracy:\t0.6599999904632569\ttime:\t0:00:00.086030\n",
      "epoch:\t50\ttotal loss:\t4.771563351154327\tmean accuracy:\t0.6599999904632569\ttime:\t0:00:00.066929\n",
      "epoch:\t60\ttotal loss:\t4.52126008272171\tmean accuracy:\t0.6599999785423278\ttime:\t0:00:00.067667\n",
      "epoch:\t70\ttotal loss:\t4.304783940315247\tmean accuracy:\t0.6599999904632569\ttime:\t0:00:00.065897\n",
      "epoch:\t80\ttotal loss:\t4.150878846645355\tmean accuracy:\t0.7800000071525574\ttime:\t0:00:00.075411\n",
      "epoch:\t90\ttotal loss:\t4.025420367717743\tmean accuracy:\t0.9\ttime:\t0:00:00.073547\n",
      "epoch:\t100\ttotal loss:\t3.9047794938087463\tmean accuracy:\t0.9399999856948853\ttime:\t0:00:00.067379\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "\n",
    "EPOCH_NUM = 100\n",
    "HIDDEN_SIZE = 20\n",
    "BATCH_SIZE = 20\n",
    " \n",
    "# モデルの定義\n",
    "model = NN(in_size=in_size, hidden_size=HIDDEN_SIZE, out_size=out_size)\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    " \n",
    "# 学習開始\n",
    "print(\"Train\")\n",
    "st = datetime.datetime.now()\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    # ミニバッチ学習\n",
    "    perm = np.random.permutation(N) # ランダムな整数列リストを取得\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for i in range(0, N, BATCH_SIZE): \n",
    "        x = train_x[perm[i:i+BATCH_SIZE]]\n",
    "        y = train_y[perm[i:i+BATCH_SIZE]]\n",
    "        model.reset()\n",
    "        loss, accuracy = model(x=x, y=y, train=True)\n",
    "        loss.backward()\n",
    "        loss.unchain_backward()\n",
    "        total_loss += loss.data\n",
    "        total_accuracy += accuracy.data\n",
    "        optimizer.update()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        ed = datetime.datetime.now()\n",
    "        print(\"epoch:\\t{}\\ttotal loss:\\t{}\\tmean accuracy:\\t{}\\ttime:\\t{}\".format(epoch+1, total_loss, total_accuracy/(N/BATCH_SIZE), ed-st))\n",
    "        st = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict\n",
      "test data accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "print(\"Predict\")\n",
    "res = []\n",
    "for x, y in zip(test_x, test_y):\n",
    "    y_ = model(x=x.reshape(1,len(x)), train=False)\n",
    "    if y == y_:\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)\n",
    "accuracy = sum(res)/len(res)\n",
    "print(\"test data accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
