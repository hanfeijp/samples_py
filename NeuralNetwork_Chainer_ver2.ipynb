{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import Chain, optimizers, training\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "chainer 2.0.2\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"chainer\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークで排他的論理和回路のモデル ver. softmax, classifierクラス, trainingクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルクラス定義\n",
    "\n",
    "class NN(Chain):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param in_size: 入力層のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        super(NN, self).__init__(\n",
    "            xh = L.Linear(in_size, hidden_size),\n",
    "            hh = L.Linear(hidden_size, hidden_size),\n",
    "            hy = L.Linear(hidden_size, out_size)\n",
    "        )\n",
    " \n",
    "    def __call__(self, x):\n",
    "        # 順伝播の計算を行う関数\n",
    "        # :param x: 入力値\n",
    "        h = F.sigmoid(self.xh(x))\n",
    "        h = F.sigmoid(self.hh(h))\n",
    "        y = self.hy(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J100         0.699278    0.715351              0.523111       0.266667                  4.058         \n",
      "\u001b[J200         0.655703    0.711245              0.601333       0.323333                  7.65754       \n",
      "\u001b[J300         0.48834     0.538921              0.659          0.753333                  11.3765       \n",
      "\u001b[J400         0.233129    0.259909              1              1                         15.004        \n",
      "\u001b[J500         0.0424261   0.0454576             1              1                         18.7174       \n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "\n",
    "EPOCH_NUM = 500\n",
    "HIDDEN_SIZE = 5\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# 教師データ\n",
    "train_data = [\n",
    "    [[0, 0], [0]],\n",
    "    [[1, 0], [1]],\n",
    "    [[0, 1], [1]],\n",
    "    [[1, 1], [0]]\n",
    "]\n",
    " \n",
    "# 教師データを変換\n",
    "in_size = len(train_data[0][0]) #  入力サイズ\n",
    "out_size = in_size # 出力サイズ\n",
    "\n",
    "train_x, train_t = [], []\n",
    "dataset = []\n",
    "for i in range(25): # trainingのバリデーションチェック機能も確認したいので、100件に増やす\n",
    "    for x, t in train_data:\n",
    "        dataset.append((np.array(x, dtype=\"float32\"), np.array(t[0], dtype=\"int32\")))\n",
    "N = len(dataset) # 教師データの総数\n",
    "\n",
    "# モデルの定義\n",
    "model = L.Classifier(NN(in_size=in_size, hidden_size=HIDDEN_SIZE, out_size=out_size))\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "# 学習開始\n",
    "print(\"Train\")\n",
    "train, test = chainer.datasets.split_dataset_random(dataset, N-10) # 90件を学習用、10件をテスト用\n",
    "train_iter = chainer.iterators.SerialIterator(train, BATCH_SIZE)\n",
    "test_iter = chainer.iterators.SerialIterator(test, BATCH_SIZE, repeat=False, shuffle=False)\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "trainer = training.Trainer(updater, (EPOCH_NUM, \"epoch\"), out=\"result\")\n",
    "trainer.extend(training.extensions.Evaluator(test_iter, model, device=-1))\n",
    "trainer.extend(training.extensions.LogReport(trigger=(100, \"epoch\"))) # 100エポックごとにログ出力\n",
    "trainer.extend(training.extensions.PrintReport( [\"epoch\", \"main/loss\", \"validation/main/loss\", \"main/accuracy\", \"validation/main/accuracy\", \"elapsed_time\"])) # エポック、学習損失、テスト損失、学習正解率、テスト正解率、経過時間\n",
    "#trainer.extend(training.extensions.ProgressBar()) # プログレスバー出力\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict\n",
      "x:\t[1, 0]\t => \ty:\t1\n",
      "x:\t[0, 0]\t => \ty:\t0\n",
      "x:\t[1, 1]\t => \ty:\t0\n",
      "x:\t[0, 1]\t => \ty:\t1\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "print(\"\\nPredict\")\n",
    "def predict(model, x):\n",
    "    y = np.argmax(model.predictor(x=np.array([x], dtype=\"float32\")).data)\n",
    "    print(\"x:\\t{}\\t => \\ty:\\t{}\".format(x, y))\n",
    "\n",
    "predict(model, [1, 0])\n",
    "predict(model, [0, 0])\n",
    "predict(model, [1, 1])\n",
    "predict(model, [0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
