{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM\n",
    "\n",
    "ニューラルネットワークでアイリスデータ分類 ver. softmax with Chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import chainer\n",
    "from chainer import Chain, optimizers, training\n",
    "from chainer.training import extensions\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "pandas 0.20.3\n",
      "scikit-learn 0.18.2\n",
      "chainer 2.0.2\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"pandas\", \"scikit-learn\", \"chainer\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルクラス定義\n",
    "\n",
    "class NN(Chain):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param in_size: 入力層のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        super(NN, self).__init__(\n",
    "            xh = L.Linear(in_size, hidden_size),\n",
    "            hh = L.Linear(hidden_size, hidden_size),\n",
    "            hy = L.Linear(hidden_size, out_size)\n",
    "        )\n",
    " \n",
    "    def __call__(self, x):\n",
    "        # 順伝播の計算を行う関数\n",
    "        # :param x: 入力値\n",
    "        h = F.sigmoid(self.xh(x))\n",
    "        h = F.sigmoid(self.hh(h))\n",
    "        y = self.hy(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J10          1.11115     1.08219               0.365          0.39                      0.11087       \n",
      "\u001b[J20          1.03875     1.07909               0.408          0.246667                  0.237742      \n",
      "\u001b[J30          0.965692    1.02292               0.664          0.568333                  0.342483      \n",
      "\u001b[J40          0.855172    0.926833              0.7            0.6                       0.45431       \n",
      "\u001b[J50          0.720153    0.806095              0.701          0.641667                  0.567012      \n",
      "\u001b[J60          0.598405    0.696131              0.766          0.698333                  0.68277       \n",
      "\u001b[J70          0.511003    0.613085              0.878          0.805                     0.795234      \n",
      "\u001b[J80          0.444817    0.544701              0.958          0.933333                  0.901574      \n",
      "\u001b[J90          0.394639    0.488703              0.97           0.966667                  1.01357       \n",
      "\u001b[J100         0.355057    0.441564              0.97           0.966667                  1.15334       \n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "\n",
    "EPOCH_NUM = 100\n",
    "HIDDEN_SIZE = 20\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# データ\n",
    "N = 100\n",
    "in_size = 4\n",
    "out_size = 3\n",
    "iris = datasets.load_iris()\n",
    "data = pd.DataFrame(data= np.c_[iris[\"data\"], iris[\"target\"]], columns= iris[\"feature_names\"] + [\"target\"])\n",
    "data = np.array(data.values)\n",
    "dataset = []\n",
    "for d in data:\n",
    "    x = d[0:4]\n",
    "    y = d[4]\n",
    "    dataset.append((np.array(x, dtype=\"float32\"), np.array(y, dtype=\"int32\")))\n",
    "N = len(dataset)\n",
    "\n",
    "# モデルの定義\n",
    "model = L.Classifier(NN(in_size=in_size, hidden_size=HIDDEN_SIZE, out_size=out_size))\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "# 学習開始\n",
    "print(\"Train\")\n",
    "train, test = chainer.datasets.split_dataset_random(dataset, N-50) # 100件を学習用、50件をテスト用\n",
    "train_iter = chainer.iterators.SerialIterator(train, BATCH_SIZE)\n",
    "test_iter = chainer.iterators.SerialIterator(test, BATCH_SIZE, repeat=False, shuffle=False)\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "trainer = training.Trainer(updater, (EPOCH_NUM, \"epoch\"), out=\"result\")\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "trainer.extend(extensions.LogReport(trigger=(10, \"epoch\"))) # 10エポックごとにログ出力\n",
    "trainer.extend(extensions.PrintReport( [\"epoch\", \"main/loss\", \"validation/main/loss\", \"main/accuracy\", \"validation/main/accuracy\", \"elapsed_time\"])) # エポック、学習損失、テスト損失、学習正解率、テスト正解率、経過時間\n",
    "#trainer.extend(extensions.ProgressBar()) # プログレスバー出力\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict\n",
      "x\ty\tpredict\n",
      "[ 6.19999981  2.79999995  4.80000019  1.79999995] \t 2 \t 2\n",
      "[ 5.30000019  3.70000005  1.5         0.2       ] \t 0 \t 0\n",
      "[ 6.69999981  3.0999999   4.69999981  1.5       ] \t 1 \t 1\n",
      "[ 4.9000001   2.4000001   3.29999995  1.        ] \t 1 \t 1\n",
      "[ 5.69999981  3.79999995  1.70000005  0.30000001] \t 0 \t 0\n",
      "[ 5.69999981  3.          4.19999981  1.20000005] \t 1 \t 1\n",
      "[ 4.9000001  3.0999999  1.5        0.1      ] \t 0 \t 0\n",
      "[ 5.5         2.29999995  4.          1.29999995] \t 1 \t 1\n",
      "[ 6.9000001  3.0999999  4.9000001  1.5      ] \t 1 \t 1\n",
      "[ 6.5         2.79999995  4.5999999   1.5       ] \t 1 \t 1\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "print(\"Predict\")\n",
    "print(\"x\\ty\\tpredict\")\n",
    "idx = np.random.choice(N, 10)\n",
    "for i in idx:\n",
    "    x = dataset[i][0]\n",
    "    y_ = np.argmax(model.predictor(x=x.reshape(1,len(x))).data)\n",
    "    y = dataset[i][1]\n",
    "    print(x, \"\\t\", y, \"\\t\", y_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
