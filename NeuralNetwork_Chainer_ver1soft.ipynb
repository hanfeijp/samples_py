{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from chainer import Chain, Variable, cuda, optimizer, optimizers, serializers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "chainer 2.0.2\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"chainer\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークで排他的論理和回路のモデル ver. softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルクラス定義\n",
    "\n",
    "class NN(Chain):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param in_size: 入力層のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        super(NN, self).__init__(\n",
    "            xh = L.Linear(in_size, hidden_size),\n",
    "            hh = L.Linear(hidden_size, hidden_size),\n",
    "            hy = L.Linear(hidden_size, out_size)\n",
    "        )\n",
    " \n",
    "    def __call__(self, x, t=None, train=False):\n",
    "        # 順伝播の計算を行う関数\n",
    "        # :param x: 入力値\n",
    "        # :param t: 正解のラベル\n",
    "        # :param train: 学習かどうか\n",
    "        # :return: 計算した損失 or 予測したラベル\n",
    "        x = Variable(x)\n",
    "        if train:\n",
    "            t = Variable(t)\n",
    "        h = F.sigmoid(self.xh(x))\n",
    "        h = F.sigmoid(self.hh(h))\n",
    "        y = F.softmax(self.hy(h))\n",
    "        if train:\n",
    "            loss, accuracy = F.softmax_cross_entropy(y, t), F.accuracy(y, t)\n",
    "            return loss, accuracy\n",
    "        else:\n",
    "            return np.argmax(y.data)\n",
    " \n",
    "    def reset(self):\n",
    "        # 勾配の初期化\n",
    "        self.zerograds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "epoch:\t500\ttotal loss:\t0.620212197303772\tmean accuracy:\t0.5\ttime:\t0:00:00.796819\n",
      "epoch:\t1000\ttotal loss:\t0.39653003215789795\tmean accuracy:\t1.0\ttime:\t0:00:00.777004\n",
      "epoch:\t1500\ttotal loss:\t0.3356166481971741\tmean accuracy:\t1.0\ttime:\t0:00:00.766690\n",
      "epoch:\t2000\ttotal loss:\t0.32240012288093567\tmean accuracy:\t1.0\ttime:\t0:00:00.758559\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "\n",
    "EPOCH_NUM = 2000\n",
    "HIDDEN_SIZE = 5\n",
    "BATCH_SIZE = 4\n",
    " \n",
    "# 教師データ\n",
    "train_data = [\n",
    "    [[0, 0], [0]],\n",
    "    [[1, 0], [1]],\n",
    "    [[0, 1], [1]],\n",
    "    [[1, 1], [0]]\n",
    "]\n",
    " \n",
    "# 教師データを変換\n",
    "in_size = len(train_data[0][0]) #  入力サイズ\n",
    "out_size = in_size # 出力サイズ\n",
    "N = len(train_data) # 教師データの総数\n",
    "train_x, train_t = [], []\n",
    "for x, t in train_data:\n",
    "    train_x.append(x)\n",
    "    train_t.append(t[0])\n",
    "train_x = np.array(train_x, dtype=\"float32\")\n",
    "train_t = np.array(train_t, dtype=\"int32\")\n",
    " \n",
    "# モデルの定義\n",
    "model = NN(in_size=in_size, hidden_size=HIDDEN_SIZE, out_size=out_size)\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    " \n",
    "# 学習開始\n",
    "print(\"Train\")\n",
    "st = datetime.datetime.now()\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    # ミニバッチ学習\n",
    "    perm = np.random.permutation(N) # ランダムな整数列リストを取得\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for i in range(0, N, BATCH_SIZE): \n",
    "        x = train_x[perm[i:i+BATCH_SIZE]]\n",
    "        t = train_t[perm[i:i+BATCH_SIZE]]\n",
    "        model.reset()\n",
    "        loss, accuracy = model(x=x, t=t, train=True)\n",
    "        loss.backward()\n",
    "        loss.unchain_backward()\n",
    "        total_loss += loss.data\n",
    "        total_accuracy += accuracy.data\n",
    "        optimizer.update()\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        ed = datetime.datetime.now()\n",
    "        print(\"epoch:\\t{}\\ttotal loss:\\t{}\\tmean accuracy:\\t{}\\ttime:\\t{}\".format(epoch+1, total_loss, total_accuracy/(N/BATCH_SIZE), ed-st))\n",
    "        st = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict\n",
      "x:\t[1, 0]\t => \ty:\t1\n",
      "x:\t[0, 0]\t => \ty:\t0\n",
      "x:\t[1, 1]\t => \ty:\t0\n",
      "x:\t[0, 1]\t => \ty:\t1\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "print(\"\\nPredict\")\n",
    "def predict(model, x):\n",
    "    y = model(x=np.array([x], dtype=\"float32\"), train=False)\n",
    "    print(\"x:\\t{}\\t => \\ty:\\t{}\".format(x, y))\n",
    "\n",
    "predict(model, [1, 0])\n",
    "predict(model, [0, 0])\n",
    "predict(model, [1, 1])\n",
    "predict(model, [0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
