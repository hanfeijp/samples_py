{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM\n",
    "\n",
    "* ニューラルネットワークでアイリスデータ分類 with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "pandas 0.20.3\n",
      "scikit-learn 0.18.2\n",
      "torch 0.2.0.post1\n",
      "torchvision 0.1.9\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"pandas\", \"scikit-learn\", \"torch\", \"torchvision\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルクラス定義\n",
    "\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param in_size: 入力層のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        super(NN, self).__init__()\n",
    "        self.xh = torch.nn.Linear(in_size, hidden_size)\n",
    "        self.hh = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.hy = torch.nn.Linear(hidden_size, out_size)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # 順伝播を計算する関数\n",
    "        # :param x: 入力値\n",
    "        h = F.relu(self.xh(x))\n",
    "        h = F.relu(self.hh(h))\n",
    "        y = F.log_softmax(self.hy(h))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "epoch:\t10\ttotal loss:\t4.7144821882247925\taccuracy:\t0.69\tvaridation accuracy\t0.62\ttime:\t0:00:00.070227\n",
      "epoch:\t20\ttotal loss:\t3.4004125595092773\taccuracy:\t0.82\tvaridation accuracy\t0.88\ttime:\t0:00:00.055588\n",
      "epoch:\t30\ttotal loss:\t2.4579378366470337\taccuracy:\t0.95\tvaridation accuracy\t0.98\ttime:\t0:00:00.057831\n",
      "epoch:\t40\ttotal loss:\t1.9144966900348663\taccuracy:\t0.96\tvaridation accuracy\t0.98\ttime:\t0:00:00.060857\n",
      "epoch:\t50\ttotal loss:\t1.5091854631900787\taccuracy:\t0.97\tvaridation accuracy\t0.96\ttime:\t0:00:00.053361\n",
      "epoch:\t60\ttotal loss:\t1.1891621351242065\taccuracy:\t0.98\tvaridation accuracy\t0.94\ttime:\t0:00:00.053629\n",
      "epoch:\t70\ttotal loss:\t0.9551442116498947\taccuracy:\t0.97\tvaridation accuracy\t0.98\ttime:\t0:00:00.055144\n",
      "epoch:\t80\ttotal loss:\t0.792793445289135\taccuracy:\t0.98\tvaridation accuracy\t0.98\ttime:\t0:00:00.056565\n",
      "epoch:\t90\ttotal loss:\t0.6855632364749908\taccuracy:\t0.98\tvaridation accuracy\t0.98\ttime:\t0:00:00.057540\n",
      "epoch:\t100\ttotal loss:\t0.5890189185738564\taccuracy:\t0.98\tvaridation accuracy\t0.98\ttime:\t0:00:00.060571\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "\n",
    "EPOCH_NUM = 100\n",
    "HIDDEN_SIZE = 20\n",
    "BATCH_SIZE = 20\n",
    "\n",
    " # データ\n",
    "N = 100\n",
    "in_size = 4\n",
    "out_size = 3\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data= np.c_[iris[\"data\"], iris[\"target\"]], columns= iris[\"feature_names\"] + [\"target\"])\n",
    "data = np.array(data.values)\n",
    "perm = np.random.permutation(len(data))\n",
    "data = data[perm]\n",
    "train, test = np.split(data, [N])\n",
    "train_x, train_y, test_x, test_y = [], [], [], []\n",
    "for t in train:\n",
    "    train_x.append(t[0:4])\n",
    "    train_y.append(t[4])\n",
    "for t in test:\n",
    "    test_x.append(t[0:4])\n",
    "    test_y.append(t[4])\n",
    "train_x = np.array(train_x, dtype=\"float32\")\n",
    "train_y = np.array(train_y, dtype=\"int32\")\n",
    "test_x = np.array(test_x, dtype=\"float32\")\n",
    "test_y = np.array(test_y, dtype=\"int32\")\n",
    "train_x = torch.from_numpy(train_x)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "test_x = torch.from_numpy(test_x)\n",
    "test_y = torch.from_numpy(test_y)\n",
    "\n",
    "# DataLoader化\n",
    "train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    " \n",
    "# モデルの定義\n",
    "model = NN(in_size=in_size, hidden_size=HIDDEN_SIZE, out_size=out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    " \n",
    "# 学習開始\n",
    "print(\"Train\")\n",
    "st = datetime.datetime.now()\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    # ミニバッチ学習\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, y = data\n",
    "        x, y = Variable(x), Variable(y)\n",
    "        optimizer.zero_grad()\n",
    "        y_ = model(x)\n",
    "        loss = criterion(y_, y)\n",
    "        total_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        # accuracy\n",
    "        x, y = Variable(train_x), Variable(train_y)\n",
    "        _, y_ = torch.max(model(x).data, 1)\n",
    "        accuracy = sum(y.data.numpy() == y_.numpy()) / N\n",
    "        # test accuracy\n",
    "        x, y = Variable(test_x), Variable(test_y)\n",
    "        _, y_ = torch.max(model(x).data, 1)\n",
    "        test_accuracy = sum(y.data.numpy() == y_.numpy()) / len(y.data.numpy())\n",
    "        ed = datetime.datetime.now()\n",
    "        print(\"epoch:\\t{}\\ttotal loss:\\t{}\\taccuracy:\\t{}\\tvaridation accuracy\\t{}\\ttime:\\t{}\".format(epoch+1, total_loss, accuracy, test_accuracy, ed-st))\n",
    "        st = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict\n",
      "x\ty\tpredict\n",
      "[ 7.5999999  3.         6.5999999  2.0999999] \t 2 \t 2\n",
      "[ 6.69999981  3.0999999   4.4000001   1.39999998] \t 1 \t 1\n",
      "[ 5.5         2.4000001   3.79999995  1.10000002] \t 1 \t 1\n",
      "[ 4.80000019  3.4000001   1.89999998  0.2       ] \t 0 \t 0\n",
      "[ 4.80000019  3.4000001   1.89999998  0.2       ] \t 0 \t 0\n",
      "[ 7.69999981  2.79999995  6.69999981  2.        ] \t 2 \t 2\n",
      "[ 4.80000019  3.0999999   1.60000002  0.2       ] \t 0 \t 0\n",
      "[ 7.69999981  2.5999999   6.9000001   2.29999995] \t 2 \t 2\n",
      "[ 6.          3.4000001   4.5         1.60000002] \t 1 \t 1\n",
      "[ 5.          3.29999995  1.39999998  0.2       ] \t 0 \t 0\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "print(\"Predict\")\n",
    "print(\"x\\ty\\tpredict\")\n",
    "idx = np.random.choice(len(iris.data)-N, 10)\n",
    "for i in idx:\n",
    "    x, y = test_x[i], test_y[i]\n",
    "    y_ = model(x = Variable(x.view(1,len(x)))).data\n",
    "    _, y_ = torch.max(y_, 1)\n",
    "    print(x.numpy(), \"\\t\", y, \"\\t\", y_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
