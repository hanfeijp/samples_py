{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "torch 0.2.0.post1\n",
      "torchvision 0.1.9\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"torch\", \"torchvision\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークで排他的論理和回路のモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルクラス定義\n",
    "\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        # クラスの初期化\n",
    "        # :param in_size: 入力層のサイズ\n",
    "        # :param hidden_size: 隠れ層のサイズ\n",
    "        # :param out_size: 出力層のサイズ\n",
    "        super(NN, self).__init__()\n",
    "        self.xh = torch.nn.Linear(in_size, hidden_size)\n",
    "        self.hh = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.hy = torch.nn.Linear(hidden_size, out_size)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # 順伝播を計算する関数\n",
    "        # :param x: 入力値\n",
    "        h = F.relu(self.xh(x))\n",
    "        h = F.relu(self.hh(h))\n",
    "        y = F.log_softmax(self.hy(h))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "epoch:\t500\ttotal loss:\t0.27735090255737305\ttime:\t0:00:00.495323\n",
      "epoch:\t1000\ttotal loss:\t0.05447429418563843\ttime:\t0:00:00.480774\n",
      "epoch:\t1500\ttotal loss:\t0.02309884876012802\ttime:\t0:00:00.535039\n",
      "epoch:\t2000\ttotal loss:\t0.012654023244976997\ttime:\t0:00:00.525635\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "\n",
    "EPOCH_NUM = 2000\n",
    "HIDDEN_SIZE = 5\n",
    "BATCH_SIZE = 4\n",
    " \n",
    "# 教師データ\n",
    "train_data = [\n",
    "    [[0, 0], [0]],\n",
    "    [[1, 0], [1]],\n",
    "    [[0, 1], [1]],\n",
    "    [[1, 1], [0]]\n",
    "]\n",
    " \n",
    "# 教師データを変換\n",
    "in_size = len(train_data[0][0]) #  入力サイズ\n",
    "out_size = in_size # 出力サイズ\n",
    "N = len(train_data) # 教師データの総数\n",
    "train_x, train_t = [], []\n",
    "for x, t in train_data:\n",
    "    train_x.append(x)\n",
    "    train_t.append(t[0])\n",
    "train_x = np.array(train_x, dtype=\"float32\")\n",
    "train_t = np.array(train_t, dtype=\"int32\")\n",
    "\n",
    "# DataLoader化\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_t))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    " \n",
    "# モデルの定義\n",
    "model = NN(in_size=in_size, hidden_size=HIDDEN_SIZE, out_size=out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    " \n",
    "# 学習開始\n",
    "print(\"Train\")\n",
    "st = datetime.datetime.now()\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    # ミニバッチ学習\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, t = data\n",
    "        x, t = Variable(x), Variable(t)\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x)\n",
    "        loss = criterion(y, t)\n",
    "        total_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        ed = datetime.datetime.now()\n",
    "        print(\"epoch:\\t{}\\ttotal loss:\\t{}\\ttime:\\t{}\".format(epoch+1, total_loss, ed-st))\n",
    "        st = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict\n",
      "x:\t[1, 0]\t => \ty:\t1\n",
      "x:\t[0, 0]\t => \ty:\t0\n",
      "x:\t[1, 1]\t => \ty:\t0\n",
      "x:\t[0, 1]\t => \ty:\t1\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "print(\"\\nPredict\")\n",
    "def predict(model, x):\n",
    "    x_ = np.array([x], dtype=\"float32\")\n",
    "    x_ = torch.from_numpy(x_)\n",
    "    x_ = Variable(x_)\n",
    "    y = model(x_)\n",
    "    _, y = torch.max(y.data, 1)\n",
    "    print(\"x:\\t{}\\t => \\ty:\\t{}\".format(x, y[0]))\n",
    "    \n",
    "predict(model, [1, 0])\n",
    "predict(model, [0, 0])\n",
    "predict(model, [1, 1])\n",
    "predict(model, [0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
